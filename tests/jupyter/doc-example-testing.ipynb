{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# OpenAI Function Wrapper\n",
    "\n",
    "Here we demonstrate how to use `OpenAIfunctionWrapper` to wrap a python function and use LLM to call the function with parameters.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-09 08:41:28,023 - func_ai.utils.llm_tools - DEBUG - Prompt: Say hello to John\n",
      "2023-07-09 08:41:28,027 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "2023-07-09 08:41:28,028 - openai - DEBUG - api_version=None data='{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"user\", \"content\": \"Say hello to John\"}], \"functions\": [{\"name\": \"say_hello\", \"description\": \"This is a function that says hello to the user\", \"parameters\": {\"type\": \"object\", \"properties\": {\"name\": {\"description\": \"Name of the person to say hello to\", \"type\": \"string\"}}, \"required\": [\"name\"]}}], \"function_call\": \"auto\", \"temperature\": 0.0, \"top_p\": 1.0, \"frequency_penalty\": 0.0, \"presence_penalty\": 0.0, \"max_tokens\": 256}' message='Post details'\n",
      "2023-07-09 08:41:29,161 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 \"POST /v1/chat/completions HTTP/1.1\" 200 None\n",
      "2023-07-09 08:41:29,178 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=822 request_id=390f645eb76e0de6b991d41d639c09b3 response_code=200\n",
      "2023-07-09 08:41:29,180 - func_ai.utils.llm_tools - DEBUG - Response: usage={'gpt-3.5-turbo-0613': {'prompt_tokens': 64, 'completion_tokens': 15, 'total_tokens': 79}} cost_mapping={} conversation_store=OpenAIConversationStore(conversation=[{'role': 'user', 'content': 'Say hello to John'}, <OpenAIObject at 0x119c2c0b0> JSON: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": null,\n",
      "  \"function_call\": {\n",
      "    \"name\": \"say_hello\",\n",
      "    \"arguments\": \"{\\n  \\\"name\\\": \\\"John\\\"\\n}\"\n",
      "  }\n",
      "}]) max_tokens=256 model='gpt-3.5-turbo-0613' temperature=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello John!\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'name': 'say_hello', 'description': 'This is a function that says hello to the user', 'parameters': {'type': 'object', 'properties': {'name': {'description': 'Name of the person to say hello to', 'type': 'string'}}, 'required': ['name']}}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from func_ai.utils import OpenAIFunctionWrapper, OpenAIInterface\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def say_hello(name: str):\n",
    "    \"\"\"\n",
    "    This is a function that says hello to the user\n",
    "\n",
    "    :param name: Name of the person to say hello to\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print(f\"Hello {name}!\")\n",
    "\n",
    "\n",
    "_func_wrap = OpenAIFunctionWrapper.from_python_function(say_hello, OpenAIInterface())\n",
    "\n",
    "_func_wrap.from_prompt(\"Say hello to John\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-09T05:41:29.187456Z",
     "start_time": "2023-07-09T05:41:28.021639Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also also use partials to fix sensitive or non-compliant parameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-09 09:19:00,850 - func_ai.utils.llm_tools - DEBUG - Prompt: Say hello to John\n",
      "2023-07-09 09:19:00,853 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "2023-07-09 09:19:00,853 - openai - DEBUG - api_version=None data='{\"model\": \"gpt-3.5-turbo-0613\", \"messages\": [{\"role\": \"user\", \"content\": \"Say hello to John\"}], \"functions\": [{\"name\": \"say_hello\", \"description\": \"This is a function that says hello to the user\", \"parameters\": {\"type\": \"object\", \"properties\": {}, \"required\": []}}], \"function_call\": \"auto\", \"temperature\": 0.0, \"top_p\": 1.0, \"frequency_penalty\": 0.0, \"presence_penalty\": 0.0, \"max_tokens\": 256}' message='Post details'\n",
      "2023-07-09 09:19:00,859 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)\n",
      "2023-07-09 09:19:00,889 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443\n",
      "2023-07-09 09:19:02,009 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 \"POST /v1/chat/completions HTTP/1.1\" 200 None\n",
      "2023-07-09 09:19:02,012 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=711 request_id=0dbe0a70bb073d0f1954d7e438d06519 response_code=200\n",
      "2023-07-09 09:19:02,013 - func_ai.utils.llm_tools - DEBUG - Response: usage={'gpt-3.5-turbo-0613': {'prompt_tokens': 47, 'completion_tokens': 7, 'total_tokens': 54}} cost_mapping={} conversation_store=OpenAIConversationStore(conversation=[{'role': 'user', 'content': 'Say hello to John'}, <OpenAIObject at 0x119c2c530> JSON: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": null,\n",
      "  \"function_call\": {\n",
      "    \"name\": \"say_hello\",\n",
      "    \"arguments\": \"{}\"\n",
      "  }\n",
      "}]) max_tokens=256 model='gpt-3.5-turbo-0613' temperature=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'name': 'say_hello', 'description': 'This is a function that says hello to the user', 'parameters': {'type': 'object', 'properties': {}, 'required': []}}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "_func_wrap = OpenAIFunctionWrapper.from_python_function(partial(say_hello,name=\"World\"), OpenAIInterface())\n",
    "\n",
    "_func_wrap.from_prompt(\"Say hello\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-09T06:19:02.443030Z",
     "start_time": "2023-07-09T06:19:00.852033Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
